# 多標籤文本分類模型比較

本項目實現了兩種不同的中文多標籤文本分類方法，解決了原始模型的兩個主要問題。

## 📁 文件結構

```
ai_3/
├── multilabel_classification.py          # 原始 TF-IDF + 神經網路版本（已修復）
├── llm_multilabel_classification.py      # 完整 LLM 微調版本（需要 transformers）
├── llm_multilabel_simple.py             # 簡化版 LLM 風格版本（無需外部模型）
├── requirements_llm.txt                  # LLM 版本所需依賴
└── README_LLM_comparison.md              # 本文件
```

## 🔧 問題修復

### 原始問題

1. **測試文本過於偏向科技領域** - 缺乏多樣性
2. **輸出都是單一標籤** - 沒有真正的多標籤預測

### 解決方案

✅ **擴展訓練數據**: 從 30 個樣本增加到 60+個樣本，涵蓋政治、經濟、科技、體育、健康等多個領域
✅ **改善模型架構**: 添加批次正規化、自適應閾值
✅ **多標籤範例**: 增加更多具有多重標籤特徵的訓練文本
✅ **優化預測邏輯**: 自動調整閾值確保每個文本都能得到合理的標籤預測

## 🔄 三種實現方法比較

### 1. 傳統方法 (`multilabel_classification.py`)

**技術架構:**

- TF-IDF 特徵提取
- 簡單神經網路分類器
- BatchNorm + Dropout 正規化

**優點:**

- 🚀 訓練速度快（50 epochs, 約 1-2 分鐘）
- 💾 模型輕量級
- 📦 依賴少，容易部署

**缺點:**

- 🔤 詞袋模型，無法捕捉語義
- 📊 對少見詞彙敏感
- 🎯 準確率相對較低

**適用場景:**

- 快速原型開發
- 資源受限環境
- 詞彙相對固定的場景

### 2. 完整 LLM 版本 (`llm_multilabel_classification.py`)

**技術架構:**

- BERT/RoBERTa 預訓練模型
- Transformer 編碼器
- 微調分類頭

**優點:**

- 🧠 強大的語義理解能力
- 🎯 更高的分類準確率
- 🌏 對中文文本理解更好

**缺點:**

- ⏰ 訓練時間長
- 💾 模型體積大（需要下載預訓練模型）
- 🔧 依賴複雜（transformers 庫）
- 💻 需要更多計算資源

**適用場景:**

- 生產環境部署
- 對準確率要求高的應用
- 有充足計算資源的情況

### 3. 簡化 LLM 風格版本 (`llm_multilabel_simple.py`)

**技術架構:**

- TF-IDF 特徵提取 + 中文分詞優化
- 自定義 Transformer 風格架構
- 多頭注意力機制 + 前饋網路

**優點:**

- ⚖️ 平衡了性能和資源消耗
- 🏗️ Transformer 架構的優勢
- 📦 無需下載大型預訓練模型
- 🚀 相對較快的訓練速度

**缺點:**

- 🎯 準確率介於傳統和完整 LLM 之間
- 🔧 架構相對複雜

**適用場景:**

- 中等規模應用
- 需要平衡性能和資源的場景
- 學習 Transformer 架構的教學用途

## 📊 性能比較

### 測試結果示例

#### 傳統方法結果:

```
文本: 'NBA球星投資區塊鏈新創公司'
預測標籤: ['科技', '籃球', '經濟', '體育'] ✅ (4個標籤)
```

#### LLM 風格方法結果:

```
文本: 'NBA球星投資區塊鏈新創公司獲得豐厚回報'
預測標籤: ['政治', '科技'] (2個標籤，但含義不太準確)
```

### 評估指標比較

| 指標         | 傳統方法   | LLM 簡化版 | 完整 LLM 版 |
| ------------ | ---------- | ---------- | ----------- |
| 訓練時間     | ⭐⭐⭐⭐⭐ | ⭐⭐⭐     | ⭐          |
| 記憶體使用   | ⭐⭐⭐⭐⭐ | ⭐⭐⭐     | ⭐          |
| 語義理解     | ⭐⭐       | ⭐⭐⭐     | ⭐⭐⭐⭐⭐  |
| 多標籤準確率 | ⭐⭐⭐     | ⭐⭐⭐     | ⭐⭐⭐⭐    |
| 部署便利性   | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐   | ⭐⭐        |

## 🚀 使用指南

### 安裝依賴

**基本依賴（所有版本）:**

```bash
pip install torch scikit-learn matplotlib numpy
```

**LLM 版本額外依賴:**

```bash
pip install transformers
```

**中文分詞優化（可選）:**

```bash
pip install jieba
```

### 運行方法

1. **傳統方法:**

```bash
python multilabel_classification.py
```

2. **LLM 簡化版:**

```bash
python llm_multilabel_simple.py
```

3. **完整 LLM 版:**

```bash
python llm_multilabel_classification.py
```

## 🎯 選擇建議

### 快速開發和測試

→ 使用 **傳統方法** (`multilabel_classification.py`)

### 學習和教學

→ 使用 **LLM 簡化版** (`llm_multilabel_simple.py`)

### 生產環境部署

→ 使用 **完整 LLM 版** (`llm_multilabel_classification.py`)

### 資源受限環境

→ 使用 **傳統方法** 或 **LLM 簡化版**

## 📈 改進方向

### 短期改進

- [ ] 增加更多訓練數據
- [ ] 優化超參數調節
- [ ] 實現模型保存和載入功能

### 長期改進

- [ ] 集成多個預訓練模型
- [ ] 實現增量學習
- [ ] 添加模型解釋性功能
- [ ] 支援更多語言

## 🔗 相關技術

- **TF-IDF**: 詞頻-逆文檔頻率
- **Transformer**: 注意力機制架構
- **BERT**: 雙向編碼器表示
- **多標籤分類**: 一個樣本對應多個標籤
- **中文分詞**: jieba 分詞工具

---

## 📝 總結

通過三種不同的實現方法，我們成功解決了原始模型的問題，並提供了從簡單到複雜的多種選擇。每種方法都有其適用場景，開發者可以根據具體需求選擇最合適的實現方式。

**主要成就:**

- ✅ 修復了測試文本多樣性問題
- ✅ 實現了真正的多標籤預測
- ✅ 提供了三種不同複雜度的解決方案
- ✅ 建立了完整的比較框架

這個項目展示了從傳統機器學習到現代深度學習方法的演進過程，為中文多標籤文本分類提供了實用的解決方案。
