"""
=============================================================================
é‹å‹•å½©åˆ¸è³½äº‹é æ¸¬ç³»çµ± - ä¸»è¦é‹è¡Œè…³æœ¬
åŠŸèƒ½ï¼šæ•´åˆæ•¸æ“šæ”¶é›†ã€æ¨¡å‹è¨“ç·´ã€é æ¸¬ç­‰åŠŸèƒ½çš„å®Œæ•´å·¥ä½œæµç¨‹
ä½¿ç”¨ï¼špython run_sports_prediction.py
=============================================================================
"""

import argparse
import json
import os
import sys
import warnings
from datetime import datetime

import numpy as np
import pandas as pd

# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.dirname(__file__))

from config import SUPPORTED_MODELS, config
from data_collector import SportsDataCollector
# å°å…¥è‡ªå®šç¾©æ¨¡å¡Š
from sports_prediction_llm import SportsDataGenerator, SportsPredictor

warnings.filterwarnings('ignore')

class SportsPredictionPipeline:
    """é‹å‹•é æ¸¬å®Œæ•´æµæ°´ç·š"""

    def __init__(self, model_name: str = None, use_real_data: bool = False):
        """
        åˆå§‹åŒ–é æ¸¬æµæ°´ç·š

        Args:
            model_name: é è¨“ç·´æ¨¡å‹åç¨±
            use_real_data: æ˜¯å¦ä½¿ç”¨çœŸå¯¦æ•¸æ“šæ”¶é›†å™¨
        """
        # è¨­å®šæ¨¡å‹
        if model_name and model_name in SUPPORTED_MODELS:
            config.model.model_name = SUPPORTED_MODELS[model_name]
        elif model_name:
            config.model.model_name = model_name

        # åˆå§‹åŒ–çµ„ä»¶
        self.predictor = SportsPredictor(
            model_name=config.model.model_name,
            num_labels=config.model.num_labels
        )

        self.use_real_data = use_real_data
        if use_real_data:
            self.data_collector = SportsDataCollector()
        else:
            self.data_generator = SportsDataGenerator()

        self.training_data = None
        self.model_trained = False

    def collect_training_data(self, sport: str = 'football', num_samples: int = 2000):
        """æ”¶é›†è¨“ç·´æ•¸æ“š"""

        print(f"ğŸ”„ æ”¶é›† {sport} è¨“ç·´æ•¸æ“š ({num_samples} æ¨£æœ¬)...")

        if self.use_real_data:
            # ä½¿ç”¨çœŸå¯¦æ•¸æ“šæ”¶é›†å™¨
            self.training_data = self.data_collector.prepare_training_data(
                sport=sport,
                num_samples=num_samples
            )
        else:
            # ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šç”Ÿæˆå™¨
            df = self.data_generator.generate_match_context(
                sport=sport,
                num_samples=num_samples
            )
            self.training_data = df

        print(f"âœ… æˆåŠŸæ”¶é›† {len(self.training_data)} æ¢è¨“ç·´æ•¸æ“š")

        # é¡¯ç¤ºæ•¸æ“šåˆ†å¸ƒ
        if 'result' in self.training_data.columns:
            result_counts = self.training_data['result'].value_counts()
            print("ğŸ“Š çµæœåˆ†å¸ƒ:")
            result_mapping = {0: 'å®¢å‹', 1: 'å¹³å±€', 2: 'ä¸»å‹'}
            for result, count in result_counts.items():
                label = result_mapping.get(result, f'æœªçŸ¥({result})')
                print(f"   {label}: {count} ({count/len(self.training_data)*100:.1f}%)")

        return self.training_data

    def train_model(self, num_epochs: int = None, batch_size: int = None):
        """è¨“ç·´æ¨¡å‹"""

        if self.training_data is None:
            raise ValueError("è«‹å…ˆæ”¶é›†è¨“ç·´æ•¸æ“š")

        print("ğŸš€ é–‹å§‹è¨“ç·´é‹å‹•é æ¸¬æ¨¡å‹...")

        # ä½¿ç”¨é…ç½®æˆ–å‚³å…¥çš„åƒæ•¸
        epochs = num_epochs or config.model.num_epochs
        batch = batch_size or config.model.batch_size

        # æº–å‚™æ•¸æ“š
        data_splits = self.predictor.prepare_data(self.training_data)
        train_dataset, val_dataset, test_dataset = self.predictor.create_datasets(data_splits)

        print(f"ğŸ“š æ•¸æ“šé›†å¤§å°:")
        print(f"   è¨“ç·´é›†: {len(train_dataset)}")
        print(f"   é©—è­‰é›†: {len(val_dataset)}")
        print(f"   æ¸¬è©¦é›†: {len(test_dataset)}")

        # è¨“ç·´æ¨¡å‹
        trainer = self.predictor.train(
            train_dataset,
            val_dataset,
            num_epochs=epochs,
            batch_size=batch
        )

        # è©•ä¼°æ¨¡å‹
        print("ğŸ“ˆ è©•ä¼°æ¨¡å‹æ€§èƒ½...")
        accuracy, f1, report = self.predictor.evaluate(test_dataset)

        self.model_trained = True
        print("âœ… æ¨¡å‹è¨“ç·´å®Œæˆ!")

        return {
            'accuracy': accuracy,
            'f1_score': f1,
            'classification_report': report
        }

    def predict_match(self, match_description: str, show_details: bool = True):
        """é æ¸¬å–®å ´æ¯”è³½"""

        if not self.model_trained:
            raise ValueError("è«‹å…ˆè¨“ç·´æ¨¡å‹")

        print("ğŸ”® é€²è¡Œæ¯”è³½é æ¸¬...")
        prediction = self.predictor.predict_match(match_description)

        if show_details:
            print("\n" + "="*60)
            print("ğŸ“‹ æ¯”è³½æè¿°:")
            print(match_description)
            print("\nğŸ¯ é æ¸¬çµæœ:")
            print(f"   é æ¸¬çµæœ: {prediction['prediction']}")
            print(f"   ä¿¡å¿ƒåº¦: {prediction['confidence']:.3f}")
            print("\nğŸ“Š å„çµæœæ©Ÿç‡:")
            for result, prob in prediction['probabilities'].items():
                print(f"   {result}: {prob:.3f} ({prob*100:.1f}%)")
            print("="*60)

        return prediction

    def batch_predict(self, match_descriptions: list):
        """æ‰¹é‡é æ¸¬å¤šå ´æ¯”è³½"""

        print(f"ğŸ”® æ‰¹é‡é æ¸¬ {len(match_descriptions)} å ´æ¯”è³½...")
        predictions = []

        for i, description in enumerate(match_descriptions, 1):
            print(f"\né æ¸¬ç¬¬ {i} å ´æ¯”è³½:")
            try:
                prediction = self.predict_match(description, show_details=False)
                predictions.append({
                    'match_id': i,
                    'description': description,
                    'prediction': prediction['prediction'],
                    'confidence': prediction['confidence'],
                    **prediction['probabilities']
                })
                print(f"   çµæœ: {prediction['prediction']} (ä¿¡å¿ƒåº¦: {prediction['confidence']:.3f})")
            except Exception as e:
                print(f"   âŒ é æ¸¬å¤±æ•—: {e}")
                predictions.append({
                    'match_id': i,
                    'description': description,
                    'prediction': 'ERROR',
                    'confidence': 0.0,
                    'error': str(e)
                })

        return predictions

    def save_model(self, model_path: str = None):
        """ä¿å­˜æ¨¡å‹"""

        if not self.model_trained:
            raise ValueError("è«‹å…ˆè¨“ç·´æ¨¡å‹")

        save_path = model_path or config.get_model_path()
        self.predictor.save_model(save_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")

    def load_model(self, model_path: str = None):
        """è¼‰å…¥æ¨¡å‹"""

        load_path = model_path or config.get_model_path()
        if not os.path.exists(load_path):
            raise FileNotFoundError(f"æ¨¡å‹è·¯å¾‘ä¸å­˜åœ¨: {load_path}")

        self.predictor.load_model(load_path)
        self.model_trained = True
        print(f"ğŸ“ æ¨¡å‹å·²å¾ {load_path} è¼‰å…¥")

    def interactive_mode(self):
        """äº’å‹•æ¨¡å¼"""

        print("\n" + "="*60)
        print("ğŸ® é€²å…¥äº’å‹•é æ¸¬æ¨¡å¼")
        print("è¼¸å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("="*60)

        while True:
            try:
                # ç²å–ç”¨æˆ¶è¼¸å…¥
                match_input = input("\nè«‹è¼¸å…¥æ¯”è³½æè¿°: ").strip()

                if match_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ é€€å‡ºäº’å‹•æ¨¡å¼")
                    break

                if not match_input:
                    print("âš ï¸  è«‹è¼¸å…¥æ¯”è³½æè¿°")
                    continue

                # é€²è¡Œé æ¸¬
                self.predict_match(match_input)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç”¨æˆ¶ä¸­æ–·ï¼Œé€€å‡ºäº’å‹•æ¨¡å¼")
                break
            except Exception as e:
                print(f"âŒ é æ¸¬éŒ¯èª¤: {e}")

def create_sample_predictions():
    """å‰µå»ºç¤ºä¾‹é æ¸¬"""

    sample_matches = [
        "æœ¬å ´æ¯”è³½ç”±æ›¼åŸä¸»å ´è¿æˆ°åˆ©ç‰©æµ¦ã€‚æ›¼åŸè¿‘æœŸç‹€æ…‹ç‚º8/10ï¼Œåˆ©ç‰©æµ¦è¿‘æœŸç‹€æ…‹ç‚º7/10ã€‚æ¯”è³½ç•¶å¤©å¤©æ°£æ¢ä»¶ç‚ºæ™´å¤©ï¼Œæ¯”è³½å ´åœ°ç‚ºä¸»å ´ã€‚æ›¼åŸä¸»åŠ›çƒå“¡ç‹€æ…‹excellentï¼Œåˆ©ç‰©æµ¦ä¸»åŠ›çƒå“¡ç‹€æ…‹goodã€‚é›™æ–¹éå»10æ¬¡äº¤æ‰‹ï¼Œæ›¼åŸç²å‹6å ´ã€‚æ›¼åŸè¿‘æœŸè¡¨ç¾è¼ƒä½³ï¼Œå…·æœ‰å¿ƒç†å„ªå‹¢ã€‚æ›¼åŸäº«æœ‰ä¸»å ´å„ªå‹¢ï¼Œçƒè¿·æ”¯æŒåº¦é«˜ã€‚",

        "æœ¬å ´æ¯”è³½ç”±æ¹–äººä¸»å ´è¿æˆ°å‹‡å£«ã€‚æ¹–äººè¿‘æœŸç‹€æ…‹ç‚º6/10ï¼Œå‹‡å£«è¿‘æœŸç‹€æ…‹ç‚º8/10ã€‚æ¯”è³½ç•¶å¤©å¤©æ°£æ¢ä»¶ç‚ºé™°å¤©ï¼Œæ¯”è³½å ´åœ°ç‚ºä¸»å ´ã€‚æ¹–äººä¸»åŠ›çƒå“¡ç‹€æ…‹averageï¼Œå‹‡å£«ä¸»åŠ›çƒå“¡ç‹€æ…‹excellentã€‚é›™æ–¹éå»10æ¬¡äº¤æ‰‹ï¼Œæ¹–äººç²å‹4å ´ã€‚å‹‡å£«è¿‘æœŸè¡¨ç¾è¼ƒä½³ï¼Œç‹€æ…‹æ­£ç››ã€‚æ¹–äººäº«æœ‰ä¸»å ´å„ªå‹¢ï¼Œçƒè¿·æ”¯æŒåº¦é«˜ã€‚",

        "æœ¬å ´æ¯”è³½ç”±é˜¿æ£®ç´ä¸»å ´è¿æˆ°åˆ‡çˆ¾è¥¿ã€‚é˜¿æ£®ç´è¿‘æœŸç‹€æ…‹ç‚º7/10ï¼Œåˆ‡çˆ¾è¥¿è¿‘æœŸç‹€æ…‹ç‚º5/10ã€‚æ¯”è³½ç•¶å¤©å¤©æ°£æ¢ä»¶ç‚ºå°é›¨ï¼Œæ¯”è³½å ´åœ°ç‚ºä¸»å ´ã€‚é˜¿æ£®ç´ä¸»åŠ›çƒå“¡ç‹€æ…‹goodï¼Œåˆ‡çˆ¾è¥¿ä¸»åŠ›çƒå“¡ç‹€æ…‹averageã€‚é›™æ–¹éå»10æ¬¡äº¤æ‰‹ï¼Œé˜¿æ£®ç´ç²å‹5å ´ã€‚é˜¿æ£®ç´è¿‘æœŸè¡¨ç¾è¼ƒä½³ï¼Œå…·æœ‰å¿ƒç†å„ªå‹¢ã€‚é˜¿æ£®ç´äº«æœ‰ä¸»å ´å„ªå‹¢ï¼Œçƒè¿·æ”¯æŒåº¦é«˜ã€‚"
    ]

    return sample_matches

def main():
    """ä¸»å‡½æ•¸"""

    parser = argparse.ArgumentParser(description='é‹å‹•å½©åˆ¸è³½äº‹é æ¸¬ç³»çµ±')
    parser.add_argument('--mode', choices=['train', 'predict', 'interactive', 'demo'],
                       default='demo', help='é‹è¡Œæ¨¡å¼')
    parser.add_argument('--model', choices=list(SUPPORTED_MODELS.keys()) + ['custom'],
                       default='chinese-roberta', help='é è¨“ç·´æ¨¡å‹')
    parser.add_argument('--sport', choices=['football', 'basketball', 'baseball'],
                       default='football', help='é‹å‹•é¡å‹')
    parser.add_argument('--samples', type=int, default=2000, help='è¨“ç·´æ¨£æœ¬æ•¸é‡')
    parser.add_argument('--epochs', type=int, default=3, help='è¨“ç·´é€±æœŸ')
    parser.add_argument('--batch-size', type=int, default=16, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--real-data', action='store_true', help='ä½¿ç”¨çœŸå¯¦æ•¸æ“šæ”¶é›†å™¨')
    parser.add_argument('--model-path', type=str, help='æ¨¡å‹ä¿å­˜/è¼‰å…¥è·¯å¾‘')
    parser.add_argument('--match-text', type=str, help='è¦é æ¸¬çš„æ¯”è³½æè¿°')

    args = parser.parse_args()

    print("ğŸ† é‹å‹•å½©åˆ¸è³½äº‹é æ¸¬ç³»çµ±")
    print("="*60)
    print(f"é‹è¡Œæ¨¡å¼: {args.mode}")
    print(f"ä½¿ç”¨æ¨¡å‹: {args.model}")
    print(f"é‹å‹•é¡å‹: {args.sport}")
    if args.real_data:
        print("æ•¸æ“šä¾†æº: çœŸå¯¦æ•¸æ“šæ”¶é›†å™¨")
    else:
        print("æ•¸æ“šä¾†æº: æ¨¡æ“¬æ•¸æ“šç”Ÿæˆå™¨")
    print("="*60)

    # åˆå§‹åŒ–æµæ°´ç·š
    pipeline = SportsPredictionPipeline(
        model_name=args.model if args.model != 'custom' else None,
        use_real_data=args.real_data
    )

    try:
        if args.mode == 'train':
            # è¨“ç·´æ¨¡å¼
            pipeline.collect_training_data(args.sport, args.samples)
            results = pipeline.train_model(args.epochs, args.batch_size)

            # ä¿å­˜æ¨¡å‹
            if args.model_path:
                pipeline.save_model(args.model_path)
            else:
                pipeline.save_model()

            print(f"\nğŸ“Š è¨“ç·´çµæœ:")
            print(f"æº–ç¢ºç‡: {results['accuracy']:.4f}")
            print(f"F1åˆ†æ•¸: {results['f1_score']:.4f}")

        elif args.mode == 'predict':
            # é æ¸¬æ¨¡å¼
            if args.model_path:
                pipeline.load_model(args.model_path)
            else:
                # å¦‚æœæ²’æœ‰æŒ‡å®šæ¨¡å‹è·¯å¾‘ï¼Œå˜—è©¦è¼‰å…¥é»˜èªè·¯å¾‘
                try:
                    pipeline.load_model()
                except FileNotFoundError:
                    print("âš ï¸  æ‰¾ä¸åˆ°é è¨“ç·´æ¨¡å‹ï¼Œå°‡å…ˆé€²è¡Œè¨“ç·´...")
                    pipeline.collect_training_data(args.sport, 1000)  # ä½¿ç”¨è¼ƒå°‘æ¨£æœ¬å¿«é€Ÿè¨“ç·´
                    pipeline.train_model(2, args.batch_size)  # 2å€‹epochå¿«é€Ÿè¨“ç·´

            if args.match_text:
                # é æ¸¬æŒ‡å®šæ¯”è³½
                pipeline.predict_match(args.match_text)
            else:
                # é æ¸¬ç¤ºä¾‹æ¯”è³½
                sample_matches = create_sample_predictions()
                pipeline.batch_predict(sample_matches)

        elif args.mode == 'interactive':
            # äº’å‹•æ¨¡å¼
            if args.model_path:
                pipeline.load_model(args.model_path)
            else:
                try:
                    pipeline.load_model()
                except FileNotFoundError:
                    print("âš ï¸  æ‰¾ä¸åˆ°é è¨“ç·´æ¨¡å‹ï¼Œå°‡å…ˆé€²è¡Œè¨“ç·´...")
                    pipeline.collect_training_data(args.sport, 1000)
                    pipeline.train_model(2, args.batch_size)

            pipeline.interactive_mode()

        elif args.mode == 'demo':
            # æ¼”ç¤ºæ¨¡å¼ - å®Œæ•´æµç¨‹
            print("ğŸ¬ æ¼”ç¤ºå®Œæ•´é æ¸¬æµç¨‹...")

            # 1. æ”¶é›†æ•¸æ“š
            pipeline.collect_training_data(args.sport, args.samples)

            # 2. è¨“ç·´æ¨¡å‹
            results = pipeline.train_model(args.epochs, args.batch_size)

            # 3. é€²è¡Œé æ¸¬
            print("\nğŸ”® é€²è¡Œç¤ºä¾‹é æ¸¬...")
            sample_matches = create_sample_predictions()
            predictions = pipeline.batch_predict(sample_matches)

            # 4. ä¿å­˜çµæœ
            output_file = config.get_output_path(f'predictions_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json')
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'training_results': results,
                    'predictions': predictions,
                    'config': config.to_dict()
                }, f, ensure_ascii=False, indent=2)

            print(f"ğŸ“ çµæœå·²ä¿å­˜åˆ°: {output_file}")

            # 5. ä¿å­˜æ¨¡å‹
            pipeline.save_model()

    except Exception as e:
        print(f"âŒ é‹è¡ŒéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return 1

    print("\nâœ… ç¨‹åºåŸ·è¡Œå®Œæˆ!")
    return 0

if __name__ == "__main__":
    exit(main())
